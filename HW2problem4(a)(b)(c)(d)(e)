import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. Read the data
data = pd.read_csv('C:/Users/92605/Desktop/156MachineLearning/Assignments/wine+quality/winequality_red.csv', delimiter=';')

# 2. Define input and output
X = data.drop(columns=['quality']).values  
y = data['quality'].values  

# 3. Split the dataset into training, validation, and test sets
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1,random_state=2)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1667,random_state=2)

# 4. Add a bias term to the training data
X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]  

# 5. Calculate parameters using the closed-form solution
# omega_best = (X^T * X)^(-1) * X^T * y
X_b_transpose = np.transpose(X_train_b)  # Calculate the transpose of X
X_b_transpose_dot_X_b = np.dot(X_b_transpose, X_train_b)  # Calculate X^T * X
X_b_transpose_dot_y = np.dot(X_b_transpose, y_train)  # Calculate X^T * y
omega_best = np.dot(np.linalg.inv(X_b_transpose_dot_X_b), X_b_transpose_dot_y)

# 6. Output estimated parameters
print("Estimated parameters (omega):")
print(omega_best)

# 7. Calculate the root mean square for the three sets (RMS)
y_train_predict = np.dot(X_train_b, omega_best)  # Predictions on training set
train_mse = np.mean((y_train_predict - y_train) ** 2)
train_rms = np.sqrt(train_mse)  # Calculate RMS for training set
print(f"Training set root mean square error (RMS): {train_rms:.4f}")

# Make predictions on the validation set
X_val_b = np.c_[np.ones((X_val.shape[0], 1)), X_val]  # Add bias term
y_val_predict = np.dot(X_val_b, omega_best)  # Predictions on validation set

val_mse = np.mean((y_val_predict - y_val) ** 2)
val_rms = np.sqrt(val_mse)
print(f"validation set root mean square error (RMS): {val_rms:.4f}")

# Make predictions on the test set
X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]  
y_test_predict = np.dot(X_test_b, omega_best)  
test_mse = np.mean((y_test_predict - y_test) ** 2)
test_rms = np.sqrt(test_mse)  # Calculate RMS for test set
print(f"Test set root mean square error (RMS): {test_rms:.4f}")

# 8. Plotting actual vs predicted values
plt.figure(figsize=(10, 8))
plt.scatter(y_train, y_train_predict, color='blue', alpha=0.6, s=20, label='Predicted Values')  

# Plot the reference line y=x starting from (0,0) to the max value
x_values = np.linspace(0, 10, 100) 
plt.plot(x_values, x_values, color='red', linewidth=2, label='y = x (Perfect Prediction)')

# Set x-axis and y-axis limits
plt.xlim(0, 10)  
plt.ylim(0, 10)  

# Labels and title
plt.xlabel('Actual Target Values', fontsize=12)
plt.ylabel('Predicted Target Values', fontsize=12)
plt.title('Actual vs Predicted Target Values (Training Set)', fontsize=14)
plt.legend()
plt.grid()
plt.show()
